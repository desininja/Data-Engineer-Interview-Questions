{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = time, param, value\n",
    "                machinevol,\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.withColumn('time_hours',unix.to_timestamp(col('time'),format ='YYYY-mm-dd HH'))\n",
    "\n",
    "df.groupBy(['time_hours','param'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#json file into dic\n",
    "\n",
    "import json\n",
    "json_string =\"\"\n",
    "json_dict = json.loads(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CALL name_stored(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"example\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    ('2024-10-05 12:34:56', 'param1', 10),\n",
    "    ('2024-10-05 12:45:00', 'param1', 20),\n",
    "    ('2024-10-05 13:05:00', 'param2', 30),\n",
    "    ('2024-10-05 13:30:00', 'param1', 40),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data, ['time', 'param', 'value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('time', F.to_timestamp('time'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = df.groupBy(F.date_trunc('hour',F.col('time')).alias('time_hours'), 'param') \\\n",
    "    .agg(F.avg('value').alias('avg_value'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------+---------+\n",
      "|         time_hours| param|avg_value|\n",
      "+-------------------+------+---------+\n",
      "|2024-10-05 12:00:00|param1|     15.0|\n",
      "|2024-10-05 13:00:00|param2|     30.0|\n",
      "|2024-10-05 13:00:00|param1|     40.0|\n",
      "+-------------------+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "| param|count|\n",
      "+------+-----+\n",
      "|param1|    3|\n",
      "|param2|    1|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('param').count().orderBy('count',ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, FloatType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"emp_id\", IntegerType(), True),       # Employee ID\n",
    "    StructField(\"emp_name\", StringType(), True),     # Employee Name\n",
    "    StructField(\"emp_department\", StringType(), True), # Employee Department\n",
    "    StructField(\"emp_salary\", FloatType(), True)      # Employee Salary\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    # Engineering Department\n",
    "    (1, \"Alice Johnson\", \"Engineering\", 75000.0),\n",
    "    (2, \"Bob Smith\", \"Engineering\", 80000.0),\n",
    "    (3, \"Charlie Brown\", \"Engineering\", 72000.0),\n",
    "    (4, \"David Wilson\", \"Engineering\", 68000.0),\n",
    "    (5, \"Eva Green\", \"Engineering\", 90000.0),\n",
    "    (6, \"Frank Wright\", \"Engineering\", 85000.0),\n",
    "    \n",
    "    # HR Department\n",
    "    (7, \"Gina Roberts\", \"HR\", 60000.0),\n",
    "    (8, \"Henry Ford\", \"HR\", 62000.0),\n",
    "    (9, \"Ivy Adams\", \"HR\", 58000.0),\n",
    "    (10, \"Jack Nelson\", \"HR\", 65000.0),\n",
    "    (11, \"Kathy Lee\", \"HR\", 59000.0),\n",
    "    (12, \"Laura King\", \"HR\", 61000.0),\n",
    "    \n",
    "    # Finance Department\n",
    "    (13, \"Michael Scott\", \"Finance\", 80000.0),\n",
    "    (14, \"Nina Patel\", \"Finance\", 82000.0),\n",
    "    (15, \"Oscar Martinez\", \"Finance\", 78000.0),\n",
    "    (16, \"Pam Beesly\", \"Finance\", 77000.0),\n",
    "    (17, \"Quinn Kim\", \"Finance\", 79000.0),\n",
    "    (18, \"Rita Thomas\", \"Finance\", 81000.0),\n",
    "\n",
    "    # Marketing Department\n",
    "    (19, \"Sam Brown\", \"Marketing\", 65000.0),\n",
    "    (20, \"Tina Turner\", \"Marketing\", 68000.0),\n",
    "    (21, \"Ursula White\", \"Marketing\", 67000.0),\n",
    "    (22, \"Victor Hugo\", \"Marketing\", 66000.0),\n",
    "    (23, \"Wendy Lee\", \"Marketing\", 69000.0),\n",
    "    (24, \"Xena Gold\", \"Marketing\", 72000.0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+--------------+----------+\n",
      "|emp_id|      emp_name|emp_department|emp_salary|\n",
      "+------+--------------+--------------+----------+\n",
      "|     1| Alice Johnson|   Engineering|   75000.0|\n",
      "|     2|     Bob Smith|   Engineering|   80000.0|\n",
      "|     3| Charlie Brown|   Engineering|   72000.0|\n",
      "|     4|  David Wilson|   Engineering|   68000.0|\n",
      "|     5|     Eva Green|   Engineering|   90000.0|\n",
      "|     6|  Frank Wright|   Engineering|   85000.0|\n",
      "|     7|  Gina Roberts|            HR|   60000.0|\n",
      "|     8|    Henry Ford|            HR|   62000.0|\n",
      "|     9|     Ivy Adams|            HR|   58000.0|\n",
      "|    10|   Jack Nelson|            HR|   65000.0|\n",
      "|    11|     Kathy Lee|            HR|   59000.0|\n",
      "|    12|    Laura King|            HR|   61000.0|\n",
      "|    13| Michael Scott|       Finance|   80000.0|\n",
      "|    14|    Nina Patel|       Finance|   82000.0|\n",
      "|    15|Oscar Martinez|       Finance|   78000.0|\n",
      "|    16|    Pam Beesly|       Finance|   77000.0|\n",
      "|    17|     Quinn Kim|       Finance|   79000.0|\n",
      "|    18|   Rita Thomas|       Finance|   81000.0|\n",
      "|    19|     Sam Brown|     Marketing|   65000.0|\n",
      "|    20|   Tina Turner|     Marketing|   68000.0|\n",
      "|    21|  Ursula White|     Marketing|   67000.0|\n",
      "|    22|   Victor Hugo|     Marketing|   66000.0|\n",
      "|    23|     Wendy Lee|     Marketing|   69000.0|\n",
      "|    24|     Xena Gold|     Marketing|   72000.0|\n",
      "+------+--------------+--------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "third_highest_sal = df.orderBy(F.col('emp_salary').desc()).limit(3).tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(emp_id=14, emp_name='Nina Patel', emp_department='Finance', emp_salary=82000.0)]\n"
     ]
    }
   ],
   "source": [
    "print(third_highest_sal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = Window.orderBy(F.col('emp_salary').desc())\n",
    "\n",
    "df_with_rank = df.withColumn('rank',F.dense_rank().over(window))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+--------------+----------+----+\n",
      "|emp_id|  emp_name|emp_department|emp_salary|rank|\n",
      "+------+----------+--------------+----------+----+\n",
      "|    14|Nina Patel|       Finance|   82000.0|   3|\n",
      "+------+----------+--------------+----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_with_rank.filter(F.col('rank')==3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+--------------+----------+----+\n",
      "|emp_id|      emp_name|emp_department|emp_salary|rank|\n",
      "+------+--------------+--------------+----------+----+\n",
      "|     5|     Eva Green|   Engineering|   90000.0|   1|\n",
      "|     6|  Frank Wright|   Engineering|   85000.0|   2|\n",
      "|    14|    Nina Patel|       Finance|   82000.0|   3|\n",
      "|    18|   Rita Thomas|       Finance|   81000.0|   4|\n",
      "|     2|     Bob Smith|   Engineering|   80000.0|   5|\n",
      "|    13| Michael Scott|       Finance|   80000.0|   5|\n",
      "|    17|     Quinn Kim|       Finance|   79000.0|   6|\n",
      "|    15|Oscar Martinez|       Finance|   78000.0|   7|\n",
      "|    16|    Pam Beesly|       Finance|   77000.0|   8|\n",
      "|     1| Alice Johnson|   Engineering|   75000.0|   9|\n",
      "|     3| Charlie Brown|   Engineering|   72000.0|  10|\n",
      "|    24|     Xena Gold|     Marketing|   72000.0|  10|\n",
      "|    23|     Wendy Lee|     Marketing|   69000.0|  11|\n",
      "|     4|  David Wilson|   Engineering|   68000.0|  12|\n",
      "|    20|   Tina Turner|     Marketing|   68000.0|  12|\n",
      "|    21|  Ursula White|     Marketing|   67000.0|  13|\n",
      "|    22|   Victor Hugo|     Marketing|   66000.0|  14|\n",
      "|    10|   Jack Nelson|            HR|   65000.0|  15|\n",
      "|    19|     Sam Brown|     Marketing|   65000.0|  15|\n",
      "|     8|    Henry Ford|            HR|   62000.0|  16|\n",
      "|    12|    Laura King|            HR|   61000.0|  17|\n",
      "|     7|  Gina Roberts|            HR|   60000.0|  18|\n",
      "|    11|     Kathy Lee|            HR|   59000.0|  19|\n",
      "|     9|     Ivy Adams|            HR|   58000.0|  20|\n",
      "+------+--------------+--------------+----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_with_rank.show(26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_window = Window.partitionBy('emp_department').orderBy(F.col('emp_salary').desc())\n",
    "\n",
    "df_with_part_window = df.withColumn('rank',F.dense_rank().over(part_window))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+--------------+----------+----+\n",
      "|emp_id|      emp_name|emp_department|emp_salary|rank|\n",
      "+------+--------------+--------------+----------+----+\n",
      "|     5|     Eva Green|   Engineering|   90000.0|   1|\n",
      "|     6|  Frank Wright|   Engineering|   85000.0|   2|\n",
      "|     2|     Bob Smith|   Engineering|   80000.0|   3|\n",
      "|     1| Alice Johnson|   Engineering|   75000.0|   4|\n",
      "|     3| Charlie Brown|   Engineering|   72000.0|   5|\n",
      "|     4|  David Wilson|   Engineering|   68000.0|   6|\n",
      "|    14|    Nina Patel|       Finance|   82000.0|   1|\n",
      "|    18|   Rita Thomas|       Finance|   81000.0|   2|\n",
      "|    13| Michael Scott|       Finance|   80000.0|   3|\n",
      "|    17|     Quinn Kim|       Finance|   79000.0|   4|\n",
      "|    15|Oscar Martinez|       Finance|   78000.0|   5|\n",
      "|    16|    Pam Beesly|       Finance|   77000.0|   6|\n",
      "|    10|   Jack Nelson|            HR|   65000.0|   1|\n",
      "|     8|    Henry Ford|            HR|   62000.0|   2|\n",
      "|    12|    Laura King|            HR|   61000.0|   3|\n",
      "|     7|  Gina Roberts|            HR|   60000.0|   4|\n",
      "|    11|     Kathy Lee|            HR|   59000.0|   5|\n",
      "|     9|     Ivy Adams|            HR|   58000.0|   6|\n",
      "|    24|     Xena Gold|     Marketing|   72000.0|   1|\n",
      "|    23|     Wendy Lee|     Marketing|   69000.0|   2|\n",
      "|    20|   Tina Turner|     Marketing|   68000.0|   3|\n",
      "|    21|  Ursula White|     Marketing|   67000.0|   4|\n",
      "|    22|   Victor Hugo|     Marketing|   66000.0|   5|\n",
      "|    19|     Sam Brown|     Marketing|   65000.0|   6|\n",
      "+------+--------------+--------------+----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_with_part_window.show(34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------+-------------+----------+----+\n",
      "|emp_department|emp_id|     emp_name|emp_salary|rank|\n",
      "+--------------+------+-------------+----------+----+\n",
      "|   Engineering|     2|    Bob Smith|   80000.0|   3|\n",
      "|       Finance|    13|Michael Scott|   80000.0|   3|\n",
      "|            HR|    12|   Laura King|   61000.0|   3|\n",
      "|     Marketing|    20|  Tina Turner|   68000.0|   3|\n",
      "+--------------+------+-------------+----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "third_highest_each_dept = df_with_part_window.filter(F.col('rank')==3)\n",
    "third_highest_each_dept.select('emp_department','emp_id','emp_name','emp_salary','rank').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
